"""
SQLFluffé›†æˆæœåŠ¡

é›†æˆSQLFluffå¼•æ“ï¼Œå®ç°SQLæ–‡ä»¶çš„è´¨é‡åˆ†æåŠŸèƒ½ã€‚
æä¾›ç»Ÿä¸€çš„SQLåˆ†ææ¥å£ï¼Œæ”¯æŒå¤šç§SQLæ–¹è¨€å’Œè‡ªå®šä¹‰è§„åˆ™é…ç½®ã€‚
"""

import sqlfluff
from sqlfluff.core import Linter
from typing import Dict, List, Any, Optional
from datetime import datetime
import os
from pathlib import Path

from app.core.exceptions import SQLFluffException
from app.core.logging import service_logger
from app.utils.file_utils import FileManager
from app.config.settings import get_settings

settings = get_settings()


class SQLFluffService:
    """SQLFluffé›†æˆæœåŠ¡ç±»"""
    
    def __init__(self):
        self.file_manager = FileManager()
        self.logger = service_logger
        self.default_dialect = settings.SQLFLUFF_DIALECT
        # ç”¨äºç¼“å­˜ä¸åŒæ–¹è¨€çš„Linterå®ä¾‹
        self._linter_cache: Dict[str, Linter] = {}
    
    def _get_linter(self, dialect: Optional[str] = None) -> Linter:
        """
        è·å–æŒ‡å®šæ–¹è¨€çš„Linterå®ä¾‹ï¼Œä½¿ç”¨ç¼“å­˜æœºåˆ¶æé«˜æ€§èƒ½
        
        Args:
            dialect: SQLæ–¹è¨€ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ–¹è¨€
            
        Returns:
            Linter: å¯¹åº”æ–¹è¨€çš„Linterå®ä¾‹
        """
        if dialect is None:
            dialect = self.default_dialect
            
        # ä»ç¼“å­˜ä¸­è·å–æˆ–åˆ›å»ºæ–°çš„Linter
        if dialect not in self._linter_cache:
            try:
                linter = Linter(dialect=dialect)
                
                # æ‰‹åŠ¨è¿‡æ»¤æ’ä»¶è§„åˆ™ä»¥è§£å†³SQLFluff 3.4.1ä¸­æ–¹è¨€è¿‡æ»¤çš„é—®é¢˜
                filtered_linter = self._filter_rules_by_dialect(linter, dialect)
                
                self._linter_cache[dialect] = filtered_linter
                self.logger.debug(f"åˆ›å»ºæ–°çš„Linterå®ä¾‹: {dialect}")
            except Exception as e:
                self.logger.error(f"åˆ›å»ºLinterå¤±è´¥ï¼Œæ–¹è¨€: {dialect}, é”™è¯¯: {e}")
                raise SQLFluffException("åˆ›å»ºLinter", dialect, str(e))
        
        return self._linter_cache[dialect]
    
    def _filter_rules_by_dialect(self, linter: Linter, current_dialect: str) -> Linter:
        """
        æ‰‹åŠ¨è¿‡æ»¤è§„åˆ™ï¼Œç¡®ä¿åªæœ‰é€‚ç”¨äºå½“å‰æ–¹è¨€çš„è§„åˆ™è¢«åº”ç”¨
        
        è¿™æ˜¯ä¸ºäº†è§£å†³SQLFluff 3.4.1ä¸­æ’ä»¶è§„åˆ™æ–¹è¨€è¿‡æ»¤å¤±æ•ˆçš„é—®é¢˜
        
        Args:
            linter: åŸå§‹Linterå®ä¾‹
            current_dialect: å½“å‰ä½¿ç”¨çš„æ–¹è¨€
            
        Returns:
            Linter: è¿‡æ»¤åçš„Linterå®ä¾‹
        """
        try:
            # è·å–æ‰€æœ‰è§„åˆ™
            all_rules = linter.rule_tuples()
            rules_to_exclude = []
            
            for rule in all_rules:
                # æ£€æŸ¥è§„åˆ™æ˜¯å¦éœ€è¦è¢«æ’é™¤
                should_exclude = False
                
                # æ–¹æ³•1: æ£€æŸ¥è§„åˆ™ç±»çš„æ–¹è¨€å±æ€§ï¼ˆé€‚ç”¨äºå¤§å¤šæ•°æ’ä»¶è§„åˆ™ï¼‰
                if hasattr(rule, '_rule_class'):
                    rule_class = rule._rule_class
                    if hasattr(rule_class, 'dialects') and rule_class.dialects:
                        dialects = rule_class.dialects
                        # å¦‚æœè§„åˆ™æŒ‡å®šäº†æ–¹è¨€é™åˆ¶ï¼Œä¸”å½“å‰æ–¹è¨€ä¸åœ¨å…¶ä¸­ï¼Œåˆ™æ’é™¤
                        if isinstance(dialects, (set, list, tuple)):
                            if current_dialect not in dialects:
                                should_exclude = True
                        elif isinstance(dialects, str):
                            if current_dialect != dialects:
                                should_exclude = True
                
                # æ–¹æ³•2: ç›´æ¥æ£€æŸ¥è§„åˆ™å¯¹è±¡çš„æ–¹è¨€å±æ€§ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰
                if not should_exclude and hasattr(rule, 'dialects') and rule.dialects:
                    dialects = rule.dialects
                    if isinstance(dialects, (set, list, tuple)):
                        if current_dialect not in dialects:
                            should_exclude = True
                    elif isinstance(dialects, str):
                        if current_dialect != dialects:
                            should_exclude = True
                
                # æ–¹æ³•3: åŸºäºè§„åˆ™ä»£ç çš„ç‰¹æ®Šå¤„ç†ï¼ˆé’ˆå¯¹å·²çŸ¥çš„è‡ªå®šä¹‰è§„åˆ™ï¼‰
                if not should_exclude and 'HiveCustom' in rule.code:
                    # HiveCustomè§„åˆ™åªåº”è¯¥åœ¨hiveæ–¹è¨€ä¸­åº”ç”¨
                    if current_dialect != 'hive':
                        should_exclude = True
                        self.logger.debug(f"åŸºäºè§„åˆ™ä»£ç æ’é™¤è§„åˆ™: {rule.code} (å½“å‰æ–¹è¨€: {current_dialect})")
                
                if should_exclude:
                    rules_to_exclude.append(rule.code)
                    self.logger.debug(f"è§„åˆ™ {rule.code} è¢«æ ‡è®°ä¸ºæ’é™¤ (æ–¹è¨€: {current_dialect})")
            
            # å¦‚æœæœ‰è§„åˆ™éœ€è¦æ’é™¤ï¼Œåˆ›å»ºæ–°çš„linter
            if rules_to_exclude:
                self.logger.info(f"ä¸ºæ–¹è¨€ {current_dialect} æ’é™¤äº†ä»¥ä¸‹è§„åˆ™: {rules_to_exclude}")
                
                from sqlfluff.core import Linter
                filtered_linter = Linter(
                    dialect=current_dialect,
                    exclude_rules=rules_to_exclude
                )
                
                self.logger.debug(f"å·²ä¸ºæ–¹è¨€ {current_dialect} è¿‡æ»¤è§„åˆ™ï¼Œæ’é™¤äº† {len(rules_to_exclude)} ä¸ªè§„åˆ™")
                return filtered_linter
            
            # å¦‚æœæ²¡æœ‰è§„åˆ™éœ€è¦è¿‡æ»¤ï¼Œè¿”å›åŸå§‹linter
            self.logger.debug(f"æ–¹è¨€ {current_dialect} æ— éœ€è¿‡æ»¤è§„åˆ™")
            return linter
            
        except Exception as e:
            self.logger.warning(f"è§„åˆ™è¿‡æ»¤å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹linter: {e}")
            return linter
    
    def analyze_sql_file(self, file_path: str, dialect: Optional[str] = None) -> Dict[str, Any]:
        """
        åˆ†æå•ä¸ªSQLæ–‡ä»¶
        
        Args:
            file_path: SQLæ–‡ä»¶è·¯å¾„ï¼ˆå¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ï¼‰
            dialect: SQLæ–¹è¨€ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ–¹è¨€
            
        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
        try:
            # å¤„ç†æ–‡ä»¶è·¯å¾„ - å¦‚æœæ˜¯ç»å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
            if os.path.isabs(file_path):
                # å¦‚æœæ˜¯ç»å¯¹è·¯å¾„ï¼Œå°è¯•è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
                try:
                    relative_path = self.file_manager.get_relative_path(file_path)
                except ValueError:
                    # å¦‚æœæ— æ³•è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„
                    relative_path = file_path
            else:
                relative_path = file_path
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            if not self.file_manager.file_exists(relative_path):
                raise SQLFluffException("åˆ†æSQLæ–‡ä»¶", relative_path, "æ–‡ä»¶ä¸å­˜åœ¨")
            
            # è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆå¢å¼ºç¼–ç å¤„ç†ï¼‰
            sql_content = self._read_sql_file_with_encoding_detection(relative_path)
            
            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_info = self._get_file_info(relative_path)
            
            # æ‰§è¡Œåˆ†æ
            result = self.analyze_sql_content(sql_content, os.path.basename(file_path), dialect)
            
            # æ›´æ–°æ–‡ä»¶ä¿¡æ¯
            result['file_info'].update(file_info)
            
            self.logger.debug(f"SQLæ–‡ä»¶åˆ†æå®Œæˆ: {relative_path}, æ–¹è¨€: {dialect or self.default_dialect}")
            return result
            
        except Exception as e:
            self.logger.error(f"åˆ†æSQLæ–‡ä»¶å¤±è´¥: {file_path}, æ–¹è¨€: {dialect}, é”™è¯¯: {e}")
            if isinstance(e, SQLFluffException):
                raise
            raise SQLFluffException("åˆ†æSQLæ–‡ä»¶", file_path, str(e))
    
    def analyze_sql_content_with_rules(
        self, 
        sql_content: str, 
        file_name: str = "query.sql", 
        dialect: Optional[str] = None,
        rules: Optional[List[str]] = None,
        exclude_rules: Optional[List[str]] = None,
        config_overrides: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        åˆ†æSQLå†…å®¹ï¼Œæ”¯æŒåŠ¨æ€è§„åˆ™é…ç½®
        
        Args:
            sql_content: SQLå†…å®¹
            file_name: æ–‡ä»¶åï¼ˆç”¨äºç»“æœä¸­æ˜¾ç¤ºï¼‰
            dialect: SQLæ–¹è¨€ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ–¹è¨€
            rules: å¯ç”¨çš„è§„åˆ™åˆ—è¡¨ï¼Œå¦‚["L001", "L032", "LT01"]
            exclude_rules: æ’é™¤çš„è§„åˆ™åˆ—è¡¨ï¼Œå¦‚["L016", "L034"]
            config_overrides: å…¶ä»–é…ç½®è¦†ç›–ï¼Œå¦‚{"max_line_length": 120}
            
        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
        try:
            used_dialect = dialect or self.default_dialect
            
            # ğŸ”¥ ä½¿ç”¨SQLFluffç®€å•APIè¿›è¡ŒåŠ¨æ€é…ç½®
            lint_result = None
            
            # å¦‚æœæœ‰é¢å¤–çš„é…ç½®è¦†ç›–ï¼Œä½¿ç”¨FluffConfig
            if config_overrides or rules or exclude_rules:
                from sqlfluff.core import FluffConfig
                
                # æ„å»ºé…ç½®å­—å…¸
                configs = {
                    "core": {
                        "dialect": used_dialect,
                        **(config_overrides or {})
                    }
                }
                
                # å¦‚æœæœ‰è§„åˆ™é…ç½®ï¼Œä¹Ÿæ·»åŠ åˆ°é…ç½®ä¸­
                if rules:
                    configs["core"]["rules"] = rules
                if exclude_rules:
                    configs["core"]["exclude_rules"] = exclude_rules
                    
                config = FluffConfig(configs=configs)
                lint_result = sqlfluff.lint(sql_content, config=config)
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                lint_result = sqlfluff.lint(sql_content, dialect=used_dialect)
            
            # æ ¼å¼åŒ–ç»“æœï¼ˆä½¿ç”¨ç®€å•APIæ ¼å¼åŒ–æ–¹æ³•ï¼‰
            formatted_result = self._format_sqlfluff_simple_result(
                lint_result, sql_content, file_name, used_dialect
            )
            
            # æ·»åŠ è§„åˆ™é…ç½®ä¿¡æ¯åˆ°ç»“æœä¸­
            formatted_result["analysis_metadata"].update({
                "rules_enabled": rules if rules else "all",
                "rules_excluded": exclude_rules if exclude_rules else "none",
                "config_overrides": config_overrides if config_overrides else {}
            })
            
            self.logger.debug(f"åŠ¨æ€è§„åˆ™SQLåˆ†æå®Œæˆ: {file_name}, æ–¹è¨€: {used_dialect}, è§„åˆ™: {rules}")
            return formatted_result
            
        except Exception as e:
            self.logger.error(f"åŠ¨æ€è§„åˆ™SQLåˆ†æå¤±è´¥: {file_name}, é”™è¯¯: {e}")
            raise SQLFluffException("åŠ¨æ€è§„åˆ™SQLåˆ†æ", file_name, str(e))

    def analyze_sql_content(self, sql_content: str, file_name: str = "query.sql", dialect: Optional[str] = None) -> Dict[str, Any]:
        """
        åˆ†æSQLå†…å®¹å­—ç¬¦ä¸²ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        
        Args:
            sql_content: SQLå†…å®¹
            file_name: æ–‡ä»¶åï¼ˆç”¨äºç»“æœä¸­æ˜¾ç¤ºï¼‰
            dialect: SQLæ–¹è¨€ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ–¹è¨€
            
        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
        return self.analyze_sql_content_with_rules(sql_content, file_name, dialect)

    def _original_analyze_sql_content(self, sql_content: str, file_name: str = "query.sql", dialect: Optional[str] = None) -> Dict[str, Any]:
        """
        åŸå§‹çš„åˆ†æSQLå†…å®¹æ–¹æ³•ï¼ˆä½¿ç”¨Linterï¼‰
        """
        try:
            # è·å–å¯¹åº”æ–¹è¨€çš„Linter
            linter = self._get_linter(dialect)
            used_dialect = dialect or self.default_dialect
            
            # æ‰§è¡Œåˆ†æ
            lint_result = linter.lint_string(sql_content)
            
            # å°è¯•è·å–è§£ææ ‘
            parse_tree = None
            try:
                from sqlfluff import parse
                parse_result = parse(sql_content, dialect=used_dialect)
                if parse_result:
                    parse_tree = parse_result
            except Exception as e:
                self.logger.debug(f"è·å–è§£ææ ‘å¤±è´¥: {e}")
            
            # æ ¼å¼åŒ–ç»“æœ
            result = self._format_lint_result(
                lint_result, sql_content, file_name, used_dialect, linter, parse_tree
            )
            
            self.logger.debug(f"SQLå†…å®¹åˆ†æå®Œæˆ: {file_name}, æ–¹è¨€: {used_dialect}")
            return result
            
        except Exception as e:
            self.logger.error(f"åˆ†æSQLå†…å®¹å¤±è´¥: {file_name}, æ–¹è¨€: {dialect}, é”™è¯¯: {e}")
            raise SQLFluffException("åˆ†æSQLå†…å®¹", file_name, str(e))
    
    def get_supported_dialects(self) -> List[str]:
        """
        è·å–æ”¯æŒçš„SQLæ–¹è¨€åˆ—è¡¨
        
        Returns:
            List[str]: æ”¯æŒçš„æ–¹è¨€åˆ—è¡¨
        """
        try:
            import sqlfluff
            # ä½¿ç”¨æ­£ç¡®çš„APIè·å–æ–¹è¨€åˆ—è¡¨
            dialect_tuples = sqlfluff.list_dialects()
            return [dialect.label for dialect in dialect_tuples]
        except Exception as e:
            self.logger.error(f"è·å–æ”¯æŒçš„æ–¹è¨€å¤±è´¥: {e}")
            # è¿”å›å¸¸è§çš„æ–¹è¨€ä½œä¸ºfallback
            return [
                "mysql", "postgres", "sqlite", "bigquery", "snowflake", 
                "redshift", "oracle", "tsql", "ansi"
            ]
    
    def validate_config(self, dialect: Optional[str] = None) -> Dict[str, Any]:
        """
        éªŒè¯SQLFluffé…ç½®
        
        Args:
            dialect: è¦éªŒè¯çš„SQLæ–¹è¨€ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ–¹è¨€
            
        Returns:
            Dict[str, Any]: é…ç½®éªŒè¯ç»“æœ
        """
        try:
            used_dialect = dialect or self.default_dialect
            linter = self._get_linter(used_dialect)
            
            validation_result = {
                "is_valid": True,
                "dialect": used_dialect,
                "rules_enabled": len(linter.rule_tuples()),
                "config_source": "default",
                "errors": []
            }
            
            # æ£€æŸ¥è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
            if settings.SQLFLUFF_CONFIG_PATH:
                config_path = Path(settings.SQLFLUFF_CONFIG_PATH)
                if config_path.exists():
                    validation_result["config_source"] = str(config_path)
                else:
                    validation_result["errors"].append(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
                    validation_result["is_valid"] = False
            
            # éªŒè¯æ–¹è¨€
            supported_dialects = self.get_supported_dialects()
            if used_dialect not in supported_dialects:
                validation_result["errors"].append(f"ä¸æ”¯æŒçš„æ–¹è¨€: {used_dialect}")
                validation_result["is_valid"] = False
            
            return validation_result
            
        except Exception as e:
            self.logger.error(f"éªŒè¯é…ç½®å¤±è´¥: {e}")
            return {
                "is_valid": False,
                "errors": [str(e)]
            }
    
    def clear_linter_cache(self):
        """
        æ¸…ç©ºLinterç¼“å­˜ï¼Œåœ¨éœ€è¦é‡æ–°åŠ è½½é…ç½®æ—¶ä½¿ç”¨
        """
        self._linter_cache.clear()
        self.logger.info("Linterç¼“å­˜å·²æ¸…ç©º")
    
    def get_cached_dialects(self) -> List[str]:
        """
        è·å–å½“å‰ç¼“å­˜ä¸­çš„æ–¹è¨€åˆ—è¡¨
        
        Returns:
            List[str]: å·²ç¼“å­˜çš„æ–¹è¨€åˆ—è¡¨
        """
        return list(self._linter_cache.keys())
    
    # ç§æœ‰æ–¹æ³•
    
    def _read_sql_file_with_encoding_detection(self, relative_path: str) -> str:
        """
        ä½¿ç”¨ç¼–ç æ£€æµ‹æ¥è¯»å–SQLæ–‡ä»¶
        
        Args:
            relative_path: ç›¸å¯¹æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: æ–‡ä»¶å†…å®¹
            
        Raises:
            SQLFluffException: æ–‡ä»¶è¯»å–å¤±è´¥
        """
        abs_path = self.file_manager.get_absolute_path(relative_path)
        
        # å¸¸è§çš„ç¼–ç æ ¼å¼ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
        encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'latin-1', 'cp1252']
        
        for encoding in encodings:
            try:
                with open(abs_path, 'r', encoding=encoding) as f:
                    content = f.read()
                    self.logger.debug(f"æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è¯»å–æ–‡ä»¶: {relative_path}")
                    return content
            except UnicodeDecodeError:
                continue
            except Exception as e:
                self.logger.warning(f"ä½¿ç”¨ {encoding} ç¼–ç è¯»å–æ–‡ä»¶å¤±è´¥: {relative_path}, é”™è¯¯: {e}")
                continue
        
        # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œå°è¯•ä»¥äºŒè¿›åˆ¶æ¨¡å¼è¯»å–å¹¶æ£€æŸ¥æ–‡ä»¶å†…å®¹
        try:
            with open(abs_path, 'rb') as f:
                raw_content = f.read()
                
            # æ£€æŸ¥æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶
            if b'\x00' in raw_content:
                raise SQLFluffException(
                    "è¯»å–SQLæ–‡ä»¶", 
                    relative_path, 
                    "æ–‡ä»¶ä¼¼ä¹æ˜¯äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œä¸æ˜¯æ–‡æœ¬æ–‡ä»¶"
                )
            
            # å°è¯•ä½¿ç”¨errors='replace'æ¥è¯»å–
            try:
                content = raw_content.decode('utf-8', errors='replace')
                self.logger.warning(f"ä½¿ç”¨UTF-8æ›¿æ¢é”™è¯¯å­—ç¬¦è¯»å–æ–‡ä»¶: {relative_path}")
                return content
            except Exception:
                raise SQLFluffException(
                    "è¯»å–SQLæ–‡ä»¶", 
                    relative_path, 
                    "æ— æ³•è§£ç æ–‡ä»¶å†…å®¹ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶ç¼–ç "
                )
                
        except Exception as e:
            raise SQLFluffException("è¯»å–SQLæ–‡ä»¶", relative_path, f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
    
    def _format_lint_result(self, lint_result, sql_content: str, file_name: str, dialect: str, linter: Linter, parse_tree: Optional[Dict] = None) -> Dict[str, Any]:
        """æ ¼å¼åŒ–åˆ†æç»“æœä¸ºæ ‡å‡†JSONæ ¼å¼"""
        try:
            violations = []
            critical_count = 0
            warning_count = 0
            
            # å¤„ç†è¿è§„é¡¹ - SQLFluffè¿”å›çš„æ˜¯ä¸€ä¸ªå¤æ‚çš„ç»“æ„
            # éœ€è¦æ‰¾åˆ°å…¶ä¸­çš„SQLLintErroråˆ—è¡¨
            lint_errors = []
            
            # éå†lint_resultï¼Œæ‰¾åˆ°SQLLintErrorå¯¹è±¡
            for item in lint_result:
                # æ£€æŸ¥æ˜¯å¦æ˜¯SQLLintErrorå¯¹è±¡åˆ—è¡¨
                if isinstance(item, list):
                    for sub_item in item:
                        if hasattr(sub_item, 'line_no') and hasattr(sub_item, 'description'):
                            lint_errors.append(sub_item)
                # æ£€æŸ¥æ˜¯å¦æ˜¯å•ä¸ªSQLLintErrorå¯¹è±¡
                elif hasattr(item, 'line_no') and hasattr(item, 'description'):
                    lint_errors.append(item)
                # è®°å½•è°ƒè¯•ä¿¡æ¯
                else:
                    self.logger.debug(f"è·³è¿‡éè¿è§„é¡¹: {type(item)} - {item}")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°SQLLintErrorï¼Œè®°å½•åŸå§‹æ•°æ®ç”¨äºè°ƒè¯•
            if not lint_errors:
                self.logger.warning(f"æœªæ‰¾åˆ°SQLLintErrorå¯¹è±¡ï¼ŒåŸå§‹æ•°æ®ç±»å‹: {[type(item) for item in lint_result]}")
                self.logger.debug(f"åŸå§‹lint_resultå†…å®¹: {lint_result}")
            
            # å¤„ç†æ‰¾åˆ°çš„è¿è§„é¡¹
            for violation in lint_errors:
                try:
                    # è·å–ruleä¿¡æ¯
                    rule_code = "UNKNOWN"
                    rule_name = "unknown"
                    
                    if hasattr(violation, 'rule') and violation.rule:
                        if hasattr(violation.rule, 'code'):
                            rule_code = violation.rule.code
                        if hasattr(violation.rule, 'name'):
                            rule_name = violation.rule.name
                    
                    violation_dict = {
                        "line_no": getattr(violation, 'line_no', 0),
                        "line_pos": getattr(violation, 'line_pos', 0),
                        "code": rule_code,
                        "description": getattr(violation, 'description', 'No description'),
                        "rule": rule_name,
                        "severity": self._get_violation_severity(violation),
                        "fixable": getattr(violation, 'fixable', False)
                    }
                    
                    violations.append(violation_dict)
                    
                    # ç»Ÿè®¡ä¸¥é‡ç¨‹åº¦
                    if violation_dict["severity"] == "critical":
                        critical_count += 1
                    else:
                        warning_count += 1
                        
                except Exception as e:
                    self.logger.error(f"å¤„ç†è¿è§„é¡¹å¤±è´¥: {violation}, é”™è¯¯: {e}")
            
            # è®¡ç®—æ‘˜è¦
            total_violations = len(violations)
            file_passed = total_violations == 0
            
            # è·å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
            lines = sql_content.split('\n')
            line_count = len(lines)
            
            # æ„é€ ç»“æœ
            result = {
                "violations": violations,
                "summary": {
                    "total_violations": total_violations,
                    "critical_violations": critical_count,
                    "warning_violations": warning_count,
                    "file_passed": file_passed,
                    "success_rate": 0 if total_violations > 0 else 100
                },
                "file_info": {
                    "file_name": file_name,
                    "file_size": len(sql_content.encode('utf-8')),
                    "line_count": line_count,
                    "character_count": len(sql_content)
                },
                "analysis_metadata": {
                    "sqlfluff_version": sqlfluff.__version__,
                    "dialect": dialect,
                    "analysis_time": datetime.now().isoformat(),
                    "rules_applied": len(linter.rule_tuples())
                }
            }
            
            # æ·»åŠ è§£ææ ‘ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if parse_tree:
                # ç°åœ¨parse_treeåº”è¯¥æ€»æ˜¯é€šè¿‡_extract_parse_tree_infoå¤„ç†è¿‡çš„dictæ ¼å¼
                result["parse_tree"] = {
                    "description": "SQLFluffè§£ææ ‘ï¼Œæ˜¾ç¤ºSQLè¯­å¥çš„è¯­æ³•ç»“æ„",
                    "tree_info": parse_tree
                }
            
            return result
            
        except Exception as e:
            self.logger.error(f"æ ¼å¼åŒ–åˆ†æç»“æœå¤±è´¥: {e}")
            # è¿”å›é”™è¯¯ç»“æœ
            error_result = {
                "violations": [],
                "summary": {
                    "total_violations": 0,
                    "critical_violations": 0,
                    "warning_violations": 0,
                    "file_passed": False,
                    "error": str(e)
                },
                "file_info": {
                    "file_name": file_name,
                    "file_size": len(sql_content.encode('utf-8')) if sql_content else 0,
                    "line_count": len(sql_content.split('\n')) if sql_content else 0
                },
                "analysis_metadata": {
                    "sqlfluff_version": sqlfluff.__version__,
                    "dialect": dialect,
                    "analysis_time": datetime.now().isoformat(),
                    "error": str(e)
                }
            }
            
            # å¦‚æœæœ‰è§£ææ ‘ï¼Œä¹ŸåŒ…å«åœ¨é”™è¯¯ç»“æœä¸­
            if parse_tree:
                # ç°åœ¨parse_treeåº”è¯¥æ€»æ˜¯é€šè¿‡_extract_parse_tree_infoå¤„ç†è¿‡çš„dictæ ¼å¼
                error_result["parse_tree"] = {
                    "description": "SQLFluffè§£ææ ‘ï¼Œæ˜¾ç¤ºSQLè¯­å¥çš„è¯­æ³•ç»“æ„",
                    "tree_info": parse_tree
                }
            
            return error_result
    
    def _get_violation_severity(self, violation) -> str:
        """è·å–è¿è§„é¡¹ä¸¥é‡ç¨‹åº¦"""
        try:
            # æ ¹æ®è§„åˆ™ä»£ç åˆ¤æ–­ä¸¥é‡ç¨‹åº¦
            if hasattr(violation, 'rule') and violation.rule:
                rule_code = violation.rule.code
                
                # å…³é”®é”™è¯¯ï¼ˆå½±å“SQLæ‰§è¡Œï¼‰
                critical_rules = ['L001', 'L002', 'L003', 'L008', 'L009']
                if rule_code in critical_rules:
                    return "critical"
            
            # é»˜è®¤ä¸ºè­¦å‘Š
            return "warning"
            
        except Exception:
            return "warning"
    
    def _get_file_info(self, file_path: str) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯"""
        try:
            file_info = self.file_manager.get_file_info(file_path)
            return {
                "file_name": file_info.get("name", "unknown"),
                "file_size": file_info.get("size", 0),
                "last_modified": file_info.get("modified_time", datetime.now()).isoformat()
            }
        except Exception as e:
            self.logger.warning(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {file_path}, {e}")
            return {
                "file_name": os.path.basename(file_path),
                "file_size": 0,
                "last_modified": datetime.now().isoformat()
            }
    
    def _extract_parse_tree_info(self, parse_tree) -> Dict[str, Any]:
        """
        ä»SQLFluffè§£ææ ‘ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯
        
        Args:
            parse_tree: SQLFluffè§£ææ ‘å¯¹è±¡
            
        Returns:
            Dict[str, Any]: æ ¼å¼åŒ–çš„è§£ææ ‘ä¿¡æ¯
        """
        try:
            if not parse_tree:
                return None
            
            # è·å–å®Œæ•´çš„è§£ææ ‘ç»“æ„ï¼ˆç±»ä¼¼æ—¥å¿—ä¸­çš„æ ¼å¼ï¼‰
            detailed_tree = self._get_detailed_tree_structure(parse_tree)
            
            # è·å–åŸºæœ¬çš„å­—ç¬¦ä¸²è¡¨ç¤º
            tree_str = str(parse_tree)
            
            # æå–å…³é”®ä¿¡æ¯
            tree_info = {
                "tree_type": parse_tree.__class__.__name__ if hasattr(parse_tree, '__class__') else "unknown",
                "raw_tree": tree_str,
                "detailed_structure": detailed_tree,  # æ–°å¢ï¼šè¯¦ç»†çš„è§£ææ ‘ç»“æ„
                "contains_unparsable": "unparsable" in detailed_tree.lower() if detailed_tree else False,
                "has_syntax_errors": False
            }
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¯­æ³•é”™è¯¯
            if hasattr(parse_tree, 'get_error_segments'):
                try:
                    error_segments = parse_tree.get_error_segments()
                    if error_segments:
                        tree_info["has_syntax_errors"] = True
                        tree_info["error_segments"] = [str(seg) for seg in error_segments]
                except Exception:
                    pass
            
            # å°è¯•è·å–æ›´è¯¦ç»†çš„ç»“æ„ä¿¡æ¯
            if hasattr(parse_tree, 'segments'):
                try:
                    tree_info["segment_count"] = len(parse_tree.segments)
                except Exception:
                    pass
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸å¯è§£æçš„æ®µ
            if detailed_tree and "unparsable" in detailed_tree.lower():
                tree_info["contains_unparsable"] = True
                tree_info["has_syntax_errors"] = True
            
            return tree_info
            
        except Exception as e:
            self.logger.error(f"æå–è§£ææ ‘ä¿¡æ¯å¤±è´¥: {e}")
            return {
                "error": f"è§£ææ ‘ä¿¡æ¯æå–å¤±è´¥: {str(e)}",
                "raw_tree": str(parse_tree) if parse_tree else "None"
            }
    
    def _get_detailed_tree_structure(self, parse_tree) -> str:
        """
        è·å–è¯¦ç»†çš„è§£ææ ‘ç»“æ„ï¼Œå°è¯•ç”Ÿæˆç±»ä¼¼SQLFluffæ—¥å¿—çš„æ ¼å¼
        
        Args:
            parse_tree: SQLFluffè§£ææ ‘å¯¹è±¡
            
        Returns:
            str: æ ¼å¼åŒ–çš„è§£ææ ‘å­—ç¬¦ä¸²
        """
        try:
            if not parse_tree:
                return ""
            
            # å°è¯•å¤šç§æ–¹æ³•è·å–è¯¦ç»†çš„è§£ææ ‘ç»“æ„
            detailed_structure = None
            
            # æ–¹æ³•1: å°è¯•ä½¿ç”¨_pretty_formatæ–¹æ³•ï¼ˆSQLFluffå†…éƒ¨å¯èƒ½æœ‰ï¼‰
            if hasattr(parse_tree, '_pretty_format'):
                try:
                    detailed_structure = parse_tree._pretty_format()
                    self.logger.debug("ä½¿ç”¨_pretty_formatæ–¹æ³•è·å–è§£ææ ‘")
                except Exception as e:
                    self.logger.debug(f"_pretty_formatæ–¹æ³•å¤±è´¥: {e}")
            
            # æ–¹æ³•2: å°è¯•ä½¿ç”¨renderæ–¹æ³•ï¼Œä½†ä¼ å…¥é€‚å½“çš„å‚æ•°
            if not detailed_structure and hasattr(parse_tree, 'render'):
                try:
                    # ä¸€äº›SQLFluffç‰ˆæœ¬çš„renderæ–¹æ³•æ”¯æŒformatå‚æ•°
                    detailed_structure = parse_tree.render(format='tree')
                    self.logger.debug("ä½¿ç”¨render(format='tree')æ–¹æ³•è·å–è§£ææ ‘")
                except Exception as e:
                    try:
                        detailed_structure = parse_tree.render()
                        self.logger.debug("ä½¿ç”¨render()æ–¹æ³•è·å–è§£ææ ‘")
                    except Exception as e2:
                        self.logger.debug(f"renderæ–¹æ³•å¤±è´¥: {e}, {e2}")
            
            # æ–¹æ³•3: å°è¯•è®¿é—®å†…éƒ¨çš„treeå±æ€§æˆ–æ–¹æ³•
            if not detailed_structure:
                try:
                    # å°è¯•è®¿é—®å¯èƒ½çš„å†…éƒ¨å±æ€§
                    if hasattr(parse_tree, '_tree_repr'):
                        detailed_structure = parse_tree._tree_repr()
                    elif hasattr(parse_tree, 'tree'):
                        if callable(parse_tree.tree):
                            detailed_structure = parse_tree.tree()
                        else:
                            detailed_structure = str(parse_tree.tree)
                    self.logger.debug("ä½¿ç”¨å†…éƒ¨æ ‘è¡¨ç¤ºæ–¹æ³•è·å–è§£ææ ‘")
                except Exception as e:
                    self.logger.debug(f"å†…éƒ¨æ–¹æ³•å¤±è´¥: {e}")
            
            # æ–¹æ³•4: ä½¿ç”¨è‡ªå®šä¹‰çš„é€’å½’æ ¼å¼åŒ–
            if not detailed_structure:
                try:
                    detailed_structure = self._format_parse_tree_recursive(parse_tree, 0)
                    self.logger.debug("ä½¿ç”¨è‡ªå®šä¹‰é€’å½’æ–¹æ³•è·å–è§£ææ ‘")
                except Exception as e:
                    self.logger.debug(f"è‡ªå®šä¹‰é€’å½’æ–¹æ³•å¤±è´¥: {e}")
                    detailed_structure = str(parse_tree)
            
            return detailed_structure if detailed_structure else str(parse_tree)
            
        except Exception as e:
            self.logger.debug(f"ç”Ÿæˆè¯¦ç»†è§£ææ ‘ç»“æ„å¤±è´¥: {e}")
            return f"è§£ææ ‘ç»“æ„ç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _format_parse_tree_recursive(self, segment, level: int = 0) -> str:
        """
        é€’å½’æ ¼å¼åŒ–è§£ææ ‘ï¼Œç²¾ç¡®æ¨¡æ‹ŸSQLFluffæ—¥å¿—è¾“å‡ºæ ¼å¼
        
        Args:
            segment: è§£ææ ‘æ®µ
            level: ç¼©è¿›çº§åˆ«
            
        Returns:
            str: æ ¼å¼åŒ–çš„è§£ææ ‘å­—ç¬¦ä¸²
        """
        lines = []
        indent = "    " * level
        
        try:
            # è·å–ä½ç½®ä¿¡æ¯
            pos_info = ""
            if hasattr(segment, 'pos_marker') and segment.pos_marker:
                try:
                    line_no = getattr(segment.pos_marker, 'line_no', 1)
                    line_pos = getattr(segment.pos_marker, 'line_pos', 1) 
                    pos_info = f"[L: {line_no:3d}, P: {line_pos:3d}]"
                except:
                    pos_info = "[L:  ?, P:  ?]"
            
            # è·å–æ®µç±»å‹åç§°ï¼Œä¿æŒä¸‹åˆ’çº¿æ ¼å¼
            segment_type = segment.__class__.__name__
            # è½¬æ¢CamelCaseåˆ°snake_case
            import re
            segment_type = re.sub(r'([A-Z])', r'_\1', segment_type).lower().strip('_')
            segment_type = segment_type.replace('_segment', '')
            
            # ç‰¹æ®Šç±»å‹åç§°æ˜ å°„
            type_mappings = {
                'file': 'file',
                'statement': 'statement', 
                'delete_statement': 'delete_statement',
                'from_clause': 'from_clause',
                'from_expression': 'from_expression',
                'from_expression_element': 'from_expression_element',
                'table_expression': 'table_expression',
                'table_reference': 'table_reference',
                'alias_expression': 'alias_expression',
                'keyword': 'keyword',
                'whitespace': 'whitespace',
                'identifier': 'naked_identifier',  # SQLFluffå¸¸ç”¨naked_identifier
                'unparsable': 'unparsable',
                'word': 'word',
                'equals': 'equals',
                'numeric_literal': 'numeric_literal',
                'semicolon': 'semicolon',
                'end_of_file': '[META] end_of_file'
            }
            
            final_segment_type = type_mappings.get(segment_type, segment_type)
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯å¶å­èŠ‚ç‚¹ï¼ˆåªæœ‰å¶å­èŠ‚ç‚¹æ˜¾ç¤ºåŸå§‹å†…å®¹ï¼‰
            is_leaf = not (hasattr(segment, 'segments') and segment.segments)
            
            # è·å–åŸå§‹å†…å®¹ï¼ˆåªåœ¨å¶å­èŠ‚ç‚¹æ˜¾ç¤ºï¼‰
            raw_content = ""
            if is_leaf and hasattr(segment, 'raw') and segment.raw is not None:
                raw_content = repr(segment.raw)  # ä½¿ç”¨reprä¿ç•™å¼•å·
            
            # ç‰¹æ®Šå¤„ç†unparsableæ®µ
            if 'unparsable' in segment.__class__.__name__.lower():
                raw_content = "!! Expected: 'Nothing else in FileSegment.'"
            
            # æ„å»ºè¡Œå†…å®¹
            line_content = f"{pos_info}      |{indent}{final_segment_type}:"
            if raw_content:
                spaces_needed = max(1, 50 - len(f"{indent}{final_segment_type}:"))
                line_content += " " * spaces_needed + raw_content
                
            lines.append(line_content)
            
            # é€’å½’å¤„ç†å­æ®µ
            if hasattr(segment, 'segments') and segment.segments:
                for child_segment in segment.segments:
                    # å¤„ç†METAæ®µ
                    if hasattr(child_segment, '__class__') and 'meta' in child_segment.__class__.__name__.lower():
                        meta_type = child_segment.__class__.__name__.replace('Segment', '').lower()
                        meta_pos = ""
                        if hasattr(child_segment, 'pos_marker') and child_segment.pos_marker:
                            try:
                                line_no = getattr(child_segment.pos_marker, 'line_no', 1)
                                line_pos = getattr(child_segment.pos_marker, 'line_pos', 1)
                                meta_pos = f"[L: {line_no:3d}, P: {line_pos:3d}]"
                            except:
                                meta_pos = "[L:  ?, P:  ?]"
                        lines.append(f"{meta_pos}      |{indent}    [META] {meta_type}:")
                    else:
                        # é€’å½’å¤„ç†æ™®é€šæ®µ
                        child_lines = self._format_parse_tree_recursive(child_segment, level + 1)
                        if child_lines.strip():
                            lines.append(child_lines)
            
        except Exception as e:
            lines.append(f"{indent}Error formatting segment: {str(e)}")
        
        return '\n'.join(lines)

    def _format_sqlfluff_simple_result(self, lint_result, sql_content: str, file_name: str, dialect: str) -> Dict[str, Any]:
        """æ ¼å¼åŒ–SQLFluffç®€å•APIç»“æœä¸ºæ ‡å‡†JSONæ ¼å¼"""
        try:
            violations = []
            critical_count = 0
            warning_count = 0
            
            # SQLFluffç®€å•APIè¿”å›çš„æ˜¯è¿è§„é¡¹å­—å…¸åˆ—è¡¨
            for violation in lint_result:
                violation_dict = {
                    "line_no": violation.get("line_no", 0),
                    "line_pos": violation.get("line_pos", 0),
                    "code": violation.get("code", "UNKNOWN"),
                    "description": violation.get("description", "No description"),
                    "rule": violation.get("code", "unknown"),
                    "severity": self._get_violation_severity_from_code(violation.get("code", "")),
                    "fixable": False  # ç®€å•APIä¸æä¾›fixableä¿¡æ¯
                }
                
                violations.append(violation_dict)
                
                # ç»Ÿè®¡ä¸¥é‡ç¨‹åº¦
                if violation_dict["severity"] == "critical":
                    critical_count += 1
                else:
                    warning_count += 1
            
            # è®¡ç®—æ‘˜è¦
            total_violations = len(violations)
            file_passed = total_violations == 0
            
            # è·å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
            lines = sql_content.split('\n')
            line_count = len(lines)
            
            # æ„é€ ç»“æœ
            result = {
                "violations": violations,
                "summary": {
                    "total_violations": total_violations,
                    "critical_violations": critical_count,
                    "warning_violations": warning_count,
                    "file_passed": file_passed,
                    "success_rate": 0 if total_violations > 0 else 100
                },
                "file_info": {
                    "file_name": file_name,
                    "file_size": len(sql_content.encode('utf-8')),
                    "line_count": line_count,
                    "character_count": len(sql_content)
                },
                "analysis_metadata": {
                    "sqlfluff_version": sqlfluff.__version__,
                    "dialect": dialect,
                    "analysis_time": datetime.now().isoformat(),
                    "api_type": "simple_api"
                }
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"æ ¼å¼åŒ–SQLFluffç»“æœå¤±è´¥: {e}")
            raise SQLFluffException("æ ¼å¼åŒ–SQLFluffç»“æœ", file_name, str(e))

    def _get_violation_severity_from_code(self, rule_code: str) -> str:
        """æ ¹æ®è§„åˆ™ä»£ç åˆ¤æ–­ä¸¥é‡ç¨‹åº¦"""
        try:
            # å…³é”®é”™è¯¯ï¼ˆå½±å“SQLæ‰§è¡Œï¼‰
            critical_rules = ['L001', 'L002', 'L003', 'L008', 'L009', 'PRS01', 'TMP01']
            if rule_code in critical_rules:
                return "critical"
            
            # é»˜è®¤ä¸ºè­¦å‘Š
            return "warning"
            
        except Exception:
            return "warning"